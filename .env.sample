# Tandem Environment Configuration
# Copy to ~/.tandem/.env and uncomment to override defaults.
# Changes take effect on next session start.

# ─── LLM Backend ─────────────────────────────────────────────────────────────
# Default: "claude" (uses claude -p CLI)
# Set to an OpenAI-compatible URL to use local/remote models instead.
# Examples: http://localhost:11434 (Ollama), http://localhost:1234 (LM Studio)
# TANDEM_LLM_BACKEND=claude

# Model name. Default: "haiku" for claude backend.
# Required for URL backends (e.g. llama3.2, mistral, qwen2.5).
# TANDEM_LLM_MODEL=haiku

# Bearer token for remote endpoints. Not needed for local models.
# TANDEM_LLM_API_KEY=

# ─── Clarify ─────────────────────────────────────────────────────────────────
# Minimum prompt length (chars) before Clarify assessment triggers.
# TANDEM_CLARIFY_MIN_LENGTH=200

# Suppress "Clarified." status indicator.
# TANDEM_CLARIFY_QUIET=0

# ─── General ─────────────────────────────────────────────────────────────────
# Log verbosity: error, warn, info, debug
# TANDEM_LOG_LEVEL=info

# Location for learning profile files (Grow).
# TANDEM_PROFILE_DIR=~/.tandem/profile

# Suppress all Tandem status output.
# TANDEM_QUIET=0

# Enable/disable session-end auto-commits. Set to 0 to disable.
# TANDEM_AUTO_COMMIT=1

# Auto-squash checkpoints into your next commit. Set to 0 to disable.
# The push guard stays active regardless — pushes with auto-commits are always blocked.
# TANDEM_AUTO_SQUASH=1
